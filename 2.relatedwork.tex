\textbf{Can fact-checking content delivered via a chatbot have better corrective effectiveness(RQ1), lower effort expectations (easier to use) (RQ2), and higher intention to use and check(RQ3) compared to a webpage?}
\section{Related Work}
\subsection{Health Misinformation Fact-Checking and Fact-Checking Chatbots}
Health misinformation is a specific type of misinformation. It is usually based on anti-scientific statements, inaccurate or unproven
information, and personal anecdotes~\cite[]{teoh2019power,qi2016misinformation}  that can mislead individuals in their health decisions and have potentially harmful effects on public health.
In this paper, we follow Swire-Thompson and Lazer's~\cite[]{swire2019public} definition of health misinformation, which is information contrary to the epistemic consensus of the scientific community regarding a phenomenon.
Health misinformation in the real world is often pervasive and complex. 
On the one hand, it is widespread in interpersonal communication\cite[]{difonzo2012rumors} and mass media\cite[]{southwell2015prevalence}.
The development of the Internet and social media has amplified its dissemination\cite[]{southwell2015prevalence}; 
On the other hand, the common types of misinformation in life are typically not outright falsehoods but misleading claims\cite[]{al2018drug}. It might be subtly misleading as a result of framing, word choice, and hints\cite[]{ecker2014effects} or unintentionally caused by over-simplification, over-dramatization, and misrepresentation (i.e., confusing correlation or causation)\cite[]{lewandowsky2012misinformation}.
Therefore, in most cases individuals without professional backgrounds cannot easily identify health misinformation.
Debunking or corrective information from fact-checking organizations and professionals remains the most effective strategy to mitigate the impact of negative health misinformation at this time, compared to other interventions such as forewarning\cite[]{walter2018unring,walter2020meta,porter2021global}.

Fact-checking is the process of evaluating verifiable claims made in public statements\cite[]{brandtzaeg2017trust}, and various institutions currently give fact-checking or debunking content through their websites\cite[]{pal2019communicating}, such as Factcheck.org, Snopes, AFP FactCheck, etc.
Numerous studies have demonstrated that these corrective messages are effective in reducing health misperceptions\cite[]{walter2018unring,bode2018see,lee2020effects} and often are durable\cite[]{porter2021global}.
With the global outbreak of COVID-19, misinformation regarding the epidemic has also proliferated. 
In this context, many institutions and organizations have launched fact-checking services to provide corrective information via chatbots, such as the "WHO Health Alert"\cite[]{walwema2021health} from World Health Organization and the FactChat chatbot\footnote{\url{https://api.whatsapp.com/send/?phone=17272912606&text=hi&app_absent=0}} from the International Fact-Checking Network (IFCN). 
At present, chatbots have emerged as a promising form of combating misinformation.
For instance, in debunking false information regarding Covid-19 vaccinations, research shows that conversation with the chatbot significantly increased participants' vaccination intentions\cite[]{altay2021information}.
A rising number of such chatbots\cite[]{rodsawang2020designing,roque2021botcovid,siedlikowski2021chloe, almalki2020health} are being developed to serve the public.

Translating fact-checking content into a question-and-answer chatbot is not difficult.
Dubious claims can be set as questions, while explanations and rebuttals serve as chatbot responses.
This process can already be automated by current machine learning algorithms\cite[]{gupta2021dialfact,kotonya2020explainable}.
However, current research on fact-checking chatbots focuses on system design and usability. It does not compare with webpages to determine which interaction type is more successful in delivering fact-checking content and inspiring users' intention to verify and use.
The role of this design in the context of fact-checking is not yet clear. 
In this paper, we investigate the differences between two types of interaction, webpage and chatbot, in delivering fact-checking content. 

\subsection{Effect of Message Source}
Fact-checking can be considered as a type of persuasion\cite[]{garrett2013undermining}, and the source of information is an important heuristic cues in persuasion\cite[]{mondak1993public}.
This is because heuristic reasoning is often used as a shortcut when processing information and dealing with uncertainty\cite[]{kahan2010fears,chaiken1980heuristic}, and source cues provide the key basis for individuals when judging the credibility of information. 
When individuals perceive a message to be more believable, they are more likely to accept and be affected by it\cite{austin1994source}.

One possible potential risk of switching interaction from web to chatbot is that the chatbot itself, rather than the organization behind it, may be considered the source of the information\cite[]{ischen2020here}.
This may cause users to disbelieve the fact-checked content, rendering it ineffective for persuasion\cite[]{shin2022people}.

On the other hand, health fact check reports often provide background information about the fact checker or professional, and highlighting this information may have a positive impact on persuasiveness.
According to Varga and Bode~\cite[]{vraga2017using}, expert sources(i.e. the Centers for Disease Control and Prevention) are considered more credible than laypeople and significantly correct misconceptions.
Wang\cite[]{wang2021debunking} came to similar conclusions in the study on debunking misinformation about genetically modified food safety. These studies confirm the effectiveness of source cues in debunking misinformation.
Showing professional source cues for information may trigger expertise heuristics that imply "experts can be trusted"\cite[]{sundar2008main}.
Specifically for this study, we attract the user's attention to the expertise of the source by boldly displaying the verification professionals' title and adding avatars, in the hope of enhancing the effectiveness of persuasion or correction.

\subsection{Research Model and Hypotheses}
When accessing fact-checking content, both the interaction type and the presentation format may affect the user's experience and the effectiveness of the correction. 
We evaluate the impact of design changes to users in the following aspects.

\subsubsection*{Cognitive Effort}
Humans must expend cognitive resources when processing information to complete tasks, but such resources are limited. 
More complex tasks imply higher cognitive load and require more cognitive resources or cognitive effort. 
Edgerly\cite[]{edgerly2017seeking} has pointed out that audiences are not willing to expend extra cognitive effort to verify information. 
Therefore fact-checking tools should be easy to use and help to reduce users' cognitive load.

Previous research has found that using a chatbot can have an impact on people's cognitive effort when completing tasks. 
Brachten et al.\cite[]{brachten2020ability} showed that the group using chatbots had lower cognitive load and better task performance when solving a complex work task. 
However, Nguyen et al.\cite[]{nguyen2022user} found that the chatbot interface led to higher cognitive effort compared to the menu-based interface in two information search tasks. 
Another study compared students' experiences when utilizing a FAQ chatbot with a FAQ webpage and similarly found that chatbot users encountered a higher magnitude of barriers\cite[]{han2022faq}.
More interactions are required for users to view fact-checking content via a chatbot, and the numerous complex elements also affect the user's visual processing\cite[]{harper2009toward}, which may increase the user's cognitive load. 
In contrast, users may be more familiar with a web page and can read the content immediately, which may result in lower cognitive effort.
Higher cognitive effort is associated with lower intention to use\cite[]{venkatesh2003user}. 
This means that the chatbot interface may be not easier to use and users will have a lower intention of verifying misinformation and use.
Hence, we propose the following hypothesis:

\textbf{Hypothesis 1a}:
The chatbot interface will lead to a higher level of cognitive effort than the web page interface.

According to a systematic view, receivers put relatively little effort into judging whether to accept the conclusion of a message based on heuristic cues(i.e. source's identity) compared to reading and processing the message in detail.
This is because heuristic clues are easy to obtain and do not require detailed information processing, but are based on simple rules.
When the interface specifically highlights the identity of professionals, this may give the recipient a signal that the information is credible and thus does not require more effort to check the details.
Thus, we propose the following hypothesize:

\textbf{Hypothesis 1b}:
The interface with highlighed professonal titles will lead to a lower level of cognitive effort than the formal interface.

\subsubsection*{Fact-Checking Content Effectiveness}
\textbf{Perceived Effectiveness}.
In health communication campaigns, perceived message effectiveness is often used to respond to the likely impact of persuasive messages on target audience ratings\cite[]{noar2020does}.
Persuasion can be seen as the process of judging whether a message is effective and convincing\cite[]{dillard2007does}.
As mentioned before, audiences may not believe messages from chatbots compared to web pages, which can reduce the perceived effectiveness.
Meanwhile, the audience may trust the words of professionals more, so emphasizing the identity of professionals may have a positive impact on message effectiveness.
Therefore, we hypothesize that:
\textbf{Hypothesis 2a}:
The chatbot interface will lead to a higher level of perceived effectiveness than the web page interface.
\textbf{Hypothesis 2b}:
The interface with highlighed professonal titles will lead to a higher level of perceived effectiveness than the formal interface.
\textbf{Objective Effectiveness}
Objective effectiveness in this paper refers to the number of recipients' false beliefs that are corrected after a fact-checking content intervention.
Several previous studies have pointed out that objective message effectiveness can be predicted by perceived effectiveness\cite[]{noar2010assessing,noar2020does,dillard2007does}.
However, if receiving fact-checking results does not require much cognitive effort, recipients may process the information more easily, resulting in better corrective effects.
Therefore, we propose the following hypothesize:

\textbf{Hypothesis 3a}:
Perceived effectiveness has a positive effect on objective effectiveness.

\textbf{Hypothesis 3b}:
Cognitive effort has a positive effect on objective effectiveness.

\subsubsection*{User Intention}
\textbf{Intention to check}.
The intent to check refers to the audience's willingness to actively verify information in the future after a fact-checking content intervention.
This may be influenced by two factors, one is the perceived message effectiveness, i.e., the more credible and valid the recipient thinks the information to be, the more likely he is to actively verify the information;
The other is cognitive effort,the less resistance users encounter in the verification process, the higher intent they will to verify.
Hence, we present the following hypotheses:

\textbf{Hypothesis 3a}:
Perceived effectiveness has a positive effect on intention to check.

\textbf{Hypothesis 3b}:
Cognitive effort has a positive effect on objective effectiveness.

\textbf{Intention to use}.
Similar to the verification intent, previous studies have also confirmed the negative impact of high effort on users' willingness to use\cite[]{venkatesh2003user}.
Meanwhile, the user's intention to employ the interface to obtain information increases according to the perceived effectiveness of the information.
Besides, the intention to check can also predict the intention to use.
Thus, we propose Hypothesis 4a,4b and 4c:

\textbf{Hypothesis 4a}:
Perceived effectiveness has a positive effect on intention to use.

\textbf{Hypothesis 3b}:
Cognitive effort has a positive effect on intention to use.

\textbf{Hypothesis 4c}:
Intention to check has a positive effect on intention to use.
